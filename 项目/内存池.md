# 学习建议

完成该项目指导时间：7-10天（每天6小时）  

代码量：  
版本1：300行左右。  
版本2：600行左右。  
版本3：相较于版本2只是小改动  
测试代码：功能测试、性能测试等测试代码加起来也有600行左右  

什么人适合学习这个项目？  
●有实际C++项目开发经验的人更能够感受到内存池所带来的性能上的提升。  
●认为自己的求职项目普通，想对自己原本的项目进行拓展优化。  
●想要更深入了解C++内存管理机制。  
●校招求职者，面试官很喜欢问内存相关问题，学完这个项目后正好可以在面试官面前大展身手。  

基础要求  
熟悉C++语法，学会C++11常用特性即可  
  
建议购买一台云服务器，腾讯云或者阿里云，用来部署自己的项目 非常方便，无论是做本项目还是做其他项目，无论是自己练习，还是项目上线，都需要一台有公网Ip的独立服务器。 自己电脑安装虚拟机，不仅麻烦，进场出莫名其妙的问题。

# 1.项目介绍

项目名称：Kama-memory-pool  
项目地址：[https://github.com/youngyangyang04/memory-pool](https://github.com/youngyangyang04/memory-pool)  
开篇：内存池在实际的项目开发中较为常见，[代码随想录知识星球](https://wx.zsxq.com/group/88511825151142)将从学习的角度带大家去高效了解和学习内存池项目。  

### 什么是内存池？  
内存池是一种预分配内存并进行重复利用的技术，通过减少频繁的动态内存分配与释放操作，从而提高程序运行效率。内存池通常预先分配一块大的内存区域，将其划分为多个小块，每次需要分配内存时直接从这块区域中分配，而不是调用系统的动态分配函数（如new或malloc）。简单来说就是申请一块较大的内存块(不够继续申请)，之后将这块内存的管理放在应用层执行，减少系统调用带来的开销。  

### 为什么要做内存池？  

#### 性能优化：  
●减少动态内存分配的开销：系统调用malloc/new和free/delete涉及复杂的内存管理操作（如内存查找、碎片整理），导致性能较低，而内存池通过预分配和简单的管理逻辑显著提高了分配和释放的效率。  
●避免内存碎片：动态分配内存会产生内存碎片，尤其在大量小对象频繁分配和释放的场景中，导致的后果就是：当程序长时间运行时，由于所申请的内存块的大小不定，频繁使用时会造成大量的内存碎片从而降低程序和操作系统的性能。内存池通过管理固定大小的内存块，可以有效避免碎片化。  
●降低系统调用频率：系统级内存分配（如malloc）需要进入内核态，频繁调用会有较高的性能开销。内存池通过减少系统调用频率提高程序效率。  

#### 确定性（实时性）：  
●稳定的分配时间：使用内存池可以使分配和释放操作的耗时更加可控和稳定，适合实时性有严格要求的系统。  

### 内存池的应用场景：  

#### 高频小对象分配：  
●游戏开发：游戏中大量小对象（如粒子、子弹、NPC）的动态分配和释放非常频繁，使用内存池可以显著优化性能。  
●网络编程：网络编程中，大量请求和响应对象（如消息报文）和频繁创建和销毁非常适合使用内存池。  
●内存管理库：一些容器或数据结构（如std::vector或std::deque）在内部可能使用内存池来优化分配性能。  

#### 实时系统：  
●嵌入式设备或实时控制系统中，动态内存分配的延迟可能影响实时性，内存池提供确定性的分配性能。  

#### 高性能计算：  
●在高性能计算程序中，频繁地内存分配和释放会拖累整个程序的性能，内存池可以优化内存管理  

#### 服务器开发：  
●数据库服务器、web服务器等需要管理大量连接和请求，这些连接涉及大量内存分配，内存池能有效提升服务器性能。  

### 内存池在代码中的应用  
●对new/malloc/delete/free等动态开辟内存的系统调用进行替换  
●对STL众多容器中的空间配置器std::allocator进行替换  

### 内存池的缺点  
●初始内存占用：内存池需要预先分配较大的内存区域，可能浪费一些内存。  
●复杂性：实现和调试内存池代码比直接使用 malloc / new 更复杂。  
●不适合大型对象：对于大对象的分配可能并不划算。  

# 2.项目前置知识

### 内存池项目版本1前置知识  

#### std::allocator  
在开启内存池项目学习之前可以先了解C++中的std::allocator，它默默工作在C++STL中的所有容器的内存分配上，当你对std::allocator有所了解之后，再看内存池项目会有恍然大悟的感觉，很多内存池是按照std::allocator的标准来实现的，甚至很多开源的内存池项目可以与大多数STL容器兼容，在很多场景下，内存池是std::allocator的优化。关于std::allocator的学习参考：  
●[http://www.cnblogs.com/wpcockroach/archive/2012/05/10/2493564.html](http://www.cnblogs.com/wpcockroach/archive/2012/05/10/2493564.html)  
●[http://blog.csdn.net/justaipanda/article/details/7790355](http://blog.csdn.net/justaipanda/article/details/7790355)  
●[http://www.cplusplus.com/reference/memory/allocator/](http://www.cplusplus.com/reference/memory/allocator/)  
●[http://www.cplusplus.com/reference/memory/allocator_traits/](http://www.cplusplus.com/reference/memory/allocator_traits/)  

#### 内存碎片问题  
造成堆内存利用率很低的一个主要原因就是内存碎片化。内存碎片化就是计算机程序在运行过程中， 频繁地内存分配与释放引起的内存空间不连续性问题，可能导致内存利用率降低甚至无法分配所需的内存。内存碎片主要分为 内碎片 和 外碎片 两种类型。  
**内碎片**  
●定义：内碎片指已分配的内存块未被实际使用的部分。即程序请求的内存小于分配的内存块大小时，多余的部分形成内碎片。  
●产生原因：内存分配器通常按固定的对齐规则分配内存块（如对齐到4字节或8字节），分配大小往往是申请大小的倍数。  
●举例：程序需要13字节内存，但内存分配器按16字节对齐规则分配了16字节。多出的3字节就是内碎片  
**外碎片**  
●定义： 外碎片是指系统中有足够总量的空闲内存，但这些空闲内存不连续，无法满足一个较大的分配请求。  
●产生原因：频繁的小内存块的分配和释放导致内存分布变得零散 和 不连续的小块空闲内存无法自动组合成足够大的连续块。  
●举例：系统中有多个小块空闲内存，总量为100MB，但是由于这些空闲内存块彼此不连续，无法分配一个需要50MB的大块。  
注：内存池的固定大小块分配等机制，可以减少有效外碎片，内存池的内存分配策略根据实际需求制定的越精细产生的内碎片越少。ps：内存碎片是不可避免只能减少的。  
  
**该内存池项目哈希桶的思想借鉴了STL allocator：**  
[https://blog.csdn.net/LF_2016/article/details/53511648](https://blog.csdn.net/LF_2016/article/details/53511648)  
**具体每个小内存池的实现参照了GitHub上的项目：**  
项目：[https://github.com/cacay/MemoryPool](https://github.com/cacay/MemoryPool)（学习本文项目之前建议先看一下该项目，更基础）  
**对应文档：**[https://github.com/AngryHacker/articles/blob/master/src/code_reading/memorypool.md](https://github.com/AngryHacker/articles/blob/master/src/code_reading/memorypool.md)  
  

### 内存池项目版本2前置知识  

#### 自旋锁的概念  
自旋锁是一种 轻量级的锁机制，用于实现线程同步。当一个线程尝试获取锁时，如果锁已经被其他线程占用，它不会进入阻塞状态，而是 不断尝试获取锁，直到成功。这种“忙等”行为就叫 “自旋”。  
在 `fetchRange` 函数代码中的部分：  
​
`while (locks_[index].test_and_set(std::memory_order_acquire));`

●`test_and_set()` 是 原子操作，它将 `locks_[index]` 设置为 true，并返回锁的原始状态。  
●如果返回值表示锁已经被占用（true），线程会继续尝试获取锁（自旋）。  
●这种方式避免了线程切换的开销。  

#### 自旋锁 vs. 互斥锁  

| 自旋锁             | 互斥锁          |
| --------------- | ------------ |
| 忙等，反复尝试获取锁      | 阻塞，线程会被挂起    |
| 适合锁持有时间很短的场景    | 适合锁持有时间较长的场景 |
| 无需操作系统上下文切换，性能高 | 需要上下文切换，开销较大 |

# 3.内存池版本1项目框架

### 项目框架  
大家上网搜索内存池时，会发现搜出来的内存池项目五花八门，各不相同。许多人可能因此对内存池项目心生畏惧。但其实，当深入学习并了解完一个内存池项目后，就会发现所有的内存池本质上都在做同一件事：预先向系统申请一大片内存，并交由应用层管理，在程序运行时，内存的分配和回收都由应用层的内存池处理，从而减少系统调用。  
该项目实现的是**基于哈希映射的多种定长内存分配器（内存池中的一种）：**  
![[内存池示意图.jpg]]


主要框架如上图所示，主要就是维护一个哈希桶 `MemoryPools`，里面每项对应一个内存池 `MemoryPool`，哈希桶中每个内存池的块大小 `BlockSize` 是相同的（4096字节，当然也可以设置为不同的），但是每个内存池里每个块分割的大小（槽大小）SlotSize是不同的，依次为8,16,32,...,512字节（需要的内存超过512字节就用new/malloc），用户申请不同大小的内存就通过哈希桶的映射找到相应（槽大小） SlotSize 的内存池向其申请，比如用户分别申请8字节和12字节的内存，则经过哈希函数的计算找到槽大小为8字节的内存池和槽大小为16字节（哈希函数向上取整，因为分配给用户的内存块只能大不能小）的内存池分别分配内存给用户，这样设置的好处是可以保证内存碎片在可控范围内。  
注：到这里大家可能想问为什么用户申请超过512字节的内存就直接调用 new/malloc 等系统调用？  
答：因为内存池主要解决的是 小内存带来的内存碎片问题 和 小内存频繁申请释放带来的性能问题。但如果是用户申请较大块的内存依然选择通过内存池分配内存则会导致内存池频繁因为管理的内存不足而向系统申请内存，这样既没有起到性能优化的作用同时增加的程序的复杂度。(ps：频繁申请小内存带来的问题可参考：[https://blog.csdn.net/LF_2016/article/details/53511648](https://blog.csdn.net/LF_2016/article/details/53511648))  
介绍完大致框架之后再来看一下每个内存池的内部结构图：

![[内存池示意图2.jpg]]

主要的对象有：指向第一个可用内存块的指针Slot currentBlock（也是图中的ptr to firstBlock），被释放对象的slot链表Slot freeSlot，未使用的slot链表Slot* currentSlot，下面讲下具体的作用：  
●Slot currentBlock：内存池实际上是一个一个的 Block 以链表的形式连接起来，每一个 Block 是一块大的内存，当内存池的内存不足的时候，就会向操作系统申请新的 block 加入链表。  
●Slot freeSlot：链表里面的每一项都是对象被释放后归还给内存池的空间，内存池刚创建时 freeSlot 是空的。用户创建对象，将对象释放时，把内存归还给内存池，此时内存池不会将内存归还给系统（delete/free），而是把指向这个对象的内存的指针加到 freeSlot 链表的前面（前插），之后用户每次申请内存时，memoryPool就先在这个 freeSlot 链表里面找。  
●Slot curretSlot：用户在创建对象的时候，先检查 freeSlot 是否为空，不为空的时候直接取出一项作为分配出的空间。否则就在当前 Block 将 currentSlot 所指的内存分配出去，如果 Block 里面的内存已经使用完，就向操作系统申请一个新的 Block。  
上述两个图已经大致介绍了该项目的结构，下面我将以一个整体流程图解读的方式，给大家介绍该内存池项目：  
上述两个图已经大致介绍了该项目的结构，下面我将以一个整体流程图解读的方式，给大家介绍该内存池项目：  

![[代码随想录内存池.jpg]]

  
该项目对外提供了两个重要的接口newElement和deleteElement，分别是向内存池申请内存和将申请的内存进行回收操作。
首先介绍newElement函数，其函数声明如下：
```
template<typename T>
void deleteElement(T* p);
```
当用户想要释放对象时可调用deleteElement函数，该方法首先调用对象T的析构函数，其次同样经过哈希映射找到相应的内存池去把内存槽加入到FreeList_中。
### 项目代码  
看完上面的项目描述再看代码就很好理解了。
`MemoryPool.h`
```
namespace memoryPool
    std::mutex mutexForBlock_; // 保证多线程情况下避免不必要的重复开辟内存导致的浪费行为
};


class HashBucket
{
public:
    static void initMemoryPool();
    static MemoryPool& getMemoryPool(int index);

    static void* useMemory(size_t size)
    {
        if (size <= 0)
            return nullptr;
        if (size > MAX_SLOT_SIZE) // 大于512字节的内存，则使用new
            return operator new(size);

        // 相当于size / 8 向上取整（因为分配内存只能大不能小
        return getMemoryPool(((size + 7) / SLOT_BASE_SIZE) - 1).allocate();
    }

    static void freeMemory(void* ptr, size_t size)
    {
        if (!ptr)
            return;
        if (size > MAX_SLOT_SIZE)
        {
            operator delete(ptr);
            return;
        }

        getMemoryPool(((size + 7) / SLOT_BASE_SIZE) - 1).deallocate(ptr);
    }

    template<typename T, typename... Args> 
    friend T* newElement(Args&&... args);
    
    template<typename T>
    friend void deleteElement(T* p);
};

template<typename T, typename... Args>
T* newElement(Args&&... args)
{
    T* p = nullptr;
    // 根据元素大小选取合适的内存池分配内存
    if ((p = reinterpret_cast<T*>(HashBucket::useMemory(sizeof(T)))) != nullptr)
        // 在分配的内存上构造对象
        new(p) T(std::forward<Args>(args)...);

    return p;
}

template<typename T>
void deleteElement(T* p)
{
    // 对象析构
    if (p)
    {
        p->~T();
         // 内存回收
        HashBucket::freeMemory(reinterpret_cast<void*>(p), sizeof(T));
    }
}

} // namespace memoryPool
```
`MemoryPool.cpp`

``` 
namespace memoryPool 
    // 优先使用空闲链表中的内存槽
    if (freeList_ != nullptr)
    {
        {
            std::lock_guard<std::mutex> lock(mutexForFreeList_);
            if (freeList_ != nullptr)
            {
                Slot* temp = freeList_;
                freeList_ = freeList_->next;
                return temp;
            }
        }
    }

    Slot* temp;
    {   
        std::lock_guard<std::mutex> lock(mutexForBlock_);
        if (curSlot_ >= lastSlot_)
        {
            // 当前内存块已无内存槽可用，开辟一块新的内存
            allocateNewBlock();
        }
    
        temp = curSlot_;
        // 这里不能直接 curSlot_ += SlotSize_ 因为curSlot_是Slot*类型，所以需要除以SlotSize_再加1
        curSlot_ += SlotSize_ / sizeof(Slot);
    }
    
    return temp; 
}

void MemoryPool::deallocate(void* ptr)
{
    if (ptr)
    {
        // 回收内存，将内存通过头插法插入到空闲链表中
        std::lock_guard<std::mutex> lock(mutexForFreeList_);
        reinterpret_cast<Slot*>(ptr)->next = freeList_;
        freeList_ = reinterpret_cast<Slot*>(ptr);
    }
}

void MemoryPool::allocateNewBlock()
{   
    //std::cout << "申请一块内存块，SlotSize: " << SlotSize_ << std::endl;
    // 头插法插入新的内存块
    void* newBlock = operator new(BlockSize_);
    reinterpret_cast<Slot*>(newBlock)->next = firstBlock_;
    firstBlock_ = reinterpret_cast<Slot*>(newBlock);

    char* body = reinterpret_cast<char*>(newBlock) + sizeof(Slot*);
    size_t paddingSize = padPointer(body, SlotSize_); // 计算对齐需要填充内存的大小
    curSlot_ = reinterpret_cast<Slot*>(body + paddingSize);

    // 超过该标记位置，则说明该内存块已无内存槽可用，需向系统申请新的内存块
    lastSlot_ = reinterpret_cast<Slot*>(reinterpret_cast<size_t>(newBlock) + BlockSize_ - SlotSize_ + 1);

    freeList_ = nullptr;
}

// 让指针对齐到槽大小的倍数位置
size_t MemoryPool::padPointer(char* p, size_t align)
{
    // align 是槽大小
    return (align - reinterpret_cast<size_t>(p)) % align;
}

void HashBucket::initMemoryPool()
{
    for (int i = 0; i < MEMORY_POOL_NUM; i++)
    {
        getMemoryPool(i).init((i + 1) * SLOT_BASE_SIZE);
    }
}   

// 单例模式
MemoryPool& HashBucket::getMemoryPool(int index)
{
    static MemoryPool memoryPool[MEMORY_POOL_NUM];
    return memoryPool[index];
}

} // namespace memoryPool
```

## 项目细节思考  
**为什么内存池需要为不同类型的元素分配内存，但MemoryPool类和HashBucket类却不需要写成类模板？**  
答：因为对外提供的newElement函数和deleteElement函数是模版函数，他们根据传入的实际元素计算出元素大小后，通过HashBucket类提供的接口找到相应槽大小的MemoryPool对象，也就是说内存池和哈希桶其实不关心是为哪种类型元素申请内存，它只关心分配内存的大小。  
  
**为什么lastSlot_ 的值等于newBlock + BlockSize - sizeof(slot_type_) + 1 而不是newBlock + BlockSize - sizeof(slot_type_) ？**  
答：因为lastSlot_不是指向当前内存块的最后一个槽的地址，而是指向当前内存块中最后能存储槽的位置标志，等于或大于这个位置就代表当前内存块不足构成一个槽位以再用于存储对象了。并且newBlock + BlockSize - sizeof(slot_type_) 也不能够做为内存块最后一个槽的地址因为内存对齐的大小是不确定的，所以最后一个槽的地址也是不确定的。  
  
**内存对齐的意义是什么？**  
**1提高访问效率：**  
缓存对齐：cpu的缓存通常以固定大小的块(如64字节或128字节)为单位，如果内存对齐，数据可以完全放入一个缓冲块中，提高缓存命中率。  
内存总线对齐：现代内存通常是按块传输(如4、8、16字节)。未对齐的访问可能导致额外的内存访问，降低效率  
**2满足硬件要求**
某些硬件架构要求特定数据类型对齐，不对齐可能导致硬件异常，即使不严格要求对齐的平台，不对齐也可能导致性能下降或未定义行为。  
**3保证兼容性**
数据结构标准化：C++标准库的数据结构通常要求对齐，例如std::allocator分配的内存默认按最大对齐要求对齐。 跨平台兼容：对齐内存可以确保代码在不同架构下正确运行，避免潜在的问题。
![[内存池111.png]]

## 项目优化  
下面是对原有的项目进行高并发优化，优化点具体如下：  
●无锁数据结构：虽然这里仍然使用了锁，但可以进一步优化为无锁数据结构（如无锁队列）来管理空闲槽。  

### 无锁数据结构  
这里主要实现一个基于原子操作的无锁队列来替代原有使用互斥锁的实现。主要修改freeList_的管理方式。属于一种常用的无锁并发编程技术，通常使用于内存池或对象池管理，以避免使用锁，从而提高并发性能  
主要改进说明：  
**1原子操作：**  
a使用 std::atomic<Slot*> 替代普通指针，确保对指针的操作是原子的。  
b使用 compare_exchange_weak 实现无锁的 CAS（Compare-And-Swap）操作。  
**2内存序（Memory Ordering）：**  
amemory_order_relaxed：用于不需要同步的操作。  
bmemory_order_release：确保在此之前的所有内存写入对其他线程可见。  
cmemory_order_acquire：确保在此之后的所有内存读取能看到其他线程的写入。  
**3无锁算法：**  
apushFreeList：实现无锁入队操作，使用 CAS 确保线程安全。  
bpopFreeList：实现无锁出队操作，同样使用 CAS 确保线程安全。  
**4性能优化：**  
a移除了 mutexForFreeList_ 互斥锁，减少了锁竞争。  
b保留 mutexForBlock_ 用于新块分配，因为这是较少发生的操作。

首先修改 MemoryPool.h
```
#pragma once 

#include <cassert>
#include <cstdint>
#include <atomic>
#include <memory>

namespace memoryPool
{
#define MEMORY_POOL_NUM 64
#define SLOT_BASE_SIZE 8
#define MAX_SLOT_SIZE 512

// 修改 Slot 结构，使用原子指针
struct Slot 
{
    std::atomic<Slot*> next;
};

class MemoryPool
{
public:
    MemoryPool(size_t BlockSize = 4096);
    ~MemoryPool();
    
    void init(size_t);
    void* allocate();
    void deallocate(void*);

private:
    void allocateNewBlock();
    size_t padPointer(char* p, size_t align);
    
    // 使用CAS操作进行无锁入队和出队
    bool pushFreeList(Slot* slot);
    Slot* popFreeList();

private:
    int        BlockSize_; 
    int        SlotSize_; 
    Slot*      firstBlock_;
    Slot*      curSlot_;
    std::atomic<Slot*> freeList_;  // 修改为原子指针
    Slot*      lastSlot_;
    std::mutex mutexForBlock_;     // 仍然保留块分配的互斥锁
};

// ... 其他代码保持不变 ...

} // namespace memoryPool
```

修改 MemoryPool.cpp 实现无锁队列
```
#include "MemoryPool.h"

// ... 其他代码保持不变 ...

// 实现无锁入队操作
bool MemoryPool::pushFreeList(Slot* slot) {
    while (true) {
        // 获取当前头节点
        Slot* oldHead = freeList_.load(std::memory_order_relaxed);
        // 将新节点的 next 指向当前头节点
        slot->next.store(oldHead, std::memory_order_relaxed);
        
        // 尝试将新节点设置为头节点
        if (freeList_.compare_exchange_weak(oldHead, slot,
                                          std::memory_order_release,
                                          std::memory_order_relaxed)) {
            return true;
        }
        // CAS 失败则重试
    }
}

// 实现无锁出队操作
Slot* MemoryPool::popFreeList() {
    while (true) {
        Slot* oldHead = freeList_.load(std::memory_order_relaxed);
        if (oldHead == nullptr) {
            return nullptr;  // 队列为空
        }
        
        // 获取下一个节点
        Slot* newHead = oldHead->next.load(std::memory_order_relaxed);
        
        // 尝试更新头节点
        if (freeList_.compare_exchange_weak(oldHead, newHead,
                                          std::memory_order_acquire,
                                          std::memory_order_relaxed)) {
            return oldHead;
        }
        // CAS 失败则重试
    }
}

void* MemoryPool::allocate() {
    // 优先使用空闲链表中的内存槽
    Slot* slot = popFreeList();
    if (slot != nullptr) {
        return slot;
    }

    // 如果空闲链表为空，则分配新的内存
    std::lock_guard<std::mutex> lock(mutexForBlock_);
    if (curSlot_ >= lastSlot_) {
        allocateNewBlock();
    }
    
    Slot* result = curSlot_;
    curSlot_ = reinterpret_cast<Slot*>(
        reinterpret_cast<char*>(curSlot_) + SlotSize_
    );
    return result;
}

void MemoryPool::deallocate(void* ptr) {
    if (!ptr) return;
    
    Slot* slot = static_cast<Slot*>(ptr);
    pushFreeList(slot);
}

void MemoryPool::init(size_t size) {
    assert(size > 0);
    SlotSize_ = size;
    firstBlock_ = nullptr;
    curSlot_ = nullptr;
    freeList_.store(nullptr, std::memory_order_relaxed);
    lastSlot_ = nullptr;
}

// ... 其他代码保持不变 ...

} // namespace memoryPool
```

这个实现的主要优势是：  
1完全无锁的内存释放和重用机制  
2更好的并发性能，特别是在高并发场景下  
3避免了互斥锁带来的线程阻塞和上下文切换开销  
需要注意的是，虽然移除了互斥锁，但 CAS 操作在高并发情况下可能会发生多次重试，这是无锁算法的特性。在实际使用中，这种实现通常比基于互斥锁的实现有更好的性能表现。

# 4.内存池版本2&版本3项目框架

### 为什么实现了内存池版本1还要实现内存池版本2 ？  
因为版本1内存池的设计结构有一定的局限性，版本2选择了一种更加高性能和常用的内存池设计结构：三层缓存结构的内存池设计。  
使用这种设计结构的知名项目有：  

#### TCMalloc (Thread-Caching Malloc)  
●Google开发的内存分配器  
●用于Chrome浏览器  
●应用在Google的很多核心项目中  
结构：  
●ThreadCache：线程本地缓存  
●CentralCache：中央缓存  
●PageHeap：页面堆（对应我们的PageCache）  

#### jemalloc  
●Facebook广泛使用  
●FreeBSD的默认内存分配器  
●Redis默认使用的内存分配器  
类似的多级缓存结构：  
●TCache (Thread Cache)  
●Arena  
●Chunk/Huge  

#### ptmalloc2  
●glibc的默认内存分配器  
●Linux系统默认使用  
多层次结构：  
●Thread Arena  
●Bins  
●Top Chunk  

#### mimalloc  
●Microsoft开发的内存分配器  
●VS Code等项目在使用  
类似的分层设计：  
●Local Free Lists  
●Thread Free Lists  
●Page Based  
这种三层缓存结构的优势：  
●减少锁竞争  
●提高内存分配效率  
●降低内存碎片  
●更好的多线程扩展性  
这也是为什么这种设计被这么多大型项目采用的原因。  

### 项目整体介绍  
这个项目实现了一个高效的内存池，旨在优化内存分配和释放的性能，特别是在多线程环境下。内存池通过分层缓存架构来管理内存，主要包括以下三层： 1. ThreadCache（线程本地缓存）  
●每个线程独立的内存缓存  
●无锁操作，快速分配和释放  
●减少线程间竞争，提高并发性能  
2. CentralCache（中心缓存）  
●管理多个线程共享的内存块  
●通过自旋锁保护，确保线程安全  
●批量从PageCache获取内存，分配给ThreadCache  
3. PageCache（页缓存）  
●从操作系统获取大块内存  
●将大块内存切分成小块，供CentralCache使用  
●负责内存的回收和再利用
#### 内存池架构图
![[代码随想录内存池架构图.png]]

#### 执行流程图
```
+-------------------+
|  应用请求内存     |
+-------------------+
         |
         v
+-------------------+
|   ThreadCache     |
|-------------------|
|  检查本地缓存     |
|  有：直接分配     |
|  无：请求Central  |
+-------------------+
         |
         v
+-------------------+
|   CentralCache    |
|-------------------|
|  检查共享缓存     |
|  有：分配给Thread |
|  无：请求Page     |
+-------------------+
         |
         v
+-------------------+
|    PageCache      |
|-------------------|
|  从操作系统获取    |
|  切分成小块       |
|  返回给Central    |
+-------------------+
```

### 线程本地缓存(ThreadCache)

#### 线程本地缓存介绍  
详细介绍一下ThreadCache的设计思路和实现原理  

##### ThreadCache的定义
```
class ThreadCache
{
public:
    // 单例模式，每个线程一个实例
    static ThreadCache* getInstance()
    {
        static thread_local ThreadCache instance;
        return &instance;
    }

    void* allocate(size_t size);
    void deallocate(void* ptr, size_t size);
private:
    ThreadCache() = default;
    // 从中心缓存获取内存
    void* fetchFromCentralCache(size_t index);
    // 归还内存到中心缓存
    void returnToCentralCache(void* start, size_t size, size_t bytes);

    // 每个线程的自由链表数组
    std::array<void*, FREE_LIST_SIZE> freeList_;    
};
```
线程本地缓存的数据结构`freeList_`可视化展示
![[代码随想录中心缓存的数据结构.png]]
关键设计点  
●使用thread_local确保每个线程独立实例  
●自由链表数组管理不同大小的内存块  
●单例模式简化访问

##### 内存分配实现
```
void* ThreadCache::allocate(size_t size)
{
    // 处理0大小的分配请求
    if (size == 0)
    {
        size = ALIGNMENT; // 至少分配一个对齐大小
    }
    
    if (size > MAX_BYTES)
    {
        // 大对象直接从系统分配
        return malloc(size);
    }

    size_t index = SizeClass::getIndex(size);

    // 检查线程本地自由链表
    // 如果 freeList_[index] 不为空，表示该链表中有可用内存块
    if (void* ptr = freeList_[index])
    {
        freeList_[index] = *reinterpret_cast<void**>(ptr); // 将freeList_[index]指向的内存块的下一个内存块地址（取决于内存块的实现）
        return ptr;
    }

    // 如果线程本地自由链表为空，则从中心缓存获取一批内存
    return fetchFromCentralCache(index);
}
```
优势：  
●快速路径：直接从自由链表分配  
●无锁操作：线程本地访问  
●分级处理：大小内存分开处理

##### 从中心缓存获取内存

```
void* ThreadCache::fetchFromCentralCache(size_t index)
{
    // 从中心缓存获取一批内存
    void* result = CentralCache::getInstance().fetchRange(index);
    if (!result)
    {
        return nullptr;
    }

    // 取出一个返回给用户，剩下的放入自由链表
    void* next = *reinterpret_cast<void**>(result);
    freeList_[index] = next;
    
    return result;
}
```
设计考虑  
●批量获取：减少与中心缓存的交互  
●链表管理：维护空闲内存块链表  
●延迟加载：按需从中心缓存获取

##### 内存释放实现

```
void ThreadCache::deallocate(void* ptr, size_t size)
{
    // 大对象直接返回系统
    if (size > MAX_BYTES)
    {
        free(ptr);
        return;
    }

    // 计算索引并插入到对应自由链表头部
    size_t index = SizeClass::getIndex(size);
    *reinterpret_cast<void**>(ptr) = freeList_[index];
    freeList_[index] = ptr;
}
```

特点：  
●快速释放：直接插入线程本地缓存链表头部  
●无锁操作：提高并发性能  
●内存复用：减少系统调用

##### 为什么这样实现  
**1性能优化**  
athread_local避免了线程间同步  
b自由链表提供O(1)的分配和释放  
c批量操作减少系统调用  
**2内存管理**  
a按大小分类管理，减少碎片  
b本地缓存提高复用率  
c分级结构便于拓展  
**3并发处理**  
a无锁设计提高并发性能  
b线程隔离减少竞争  
c批量操作提高吞吐量  

##### 在内存池中的作用  
●作为第一级缓存，处理最频繁的内存请求  
●减轻中心缓存的压力  
●提供快速的内存分配和释放  
●优化多线程性能  
这种实现方式使得ThreadCache成为了内存池的性能保证，特别适合：  
1频繁的小内存分配/释放  
2多线程高并发场景  
3对延迟敏感的应用  
4需要高性能的系统

#### 项目完整实现

```
//ThreadCache.h
// 线程本地缓存
class ThreadCache
{
public:
    static ThreadCache* getInstance()
    {
        static thread_local ThreadCache instance;
        return &instance;
    }

    void* allocate(size_t size);
    void deallocate(void* ptr, size_t size);
private:
    ThreadCache() = default;
    // 从中心缓存获取内存
    void* fetchFromCentralCache(size_t index);
    // 归还内存到中心缓存
    void returnToCentralCache(void* start, size_t size, size_t bytes);
private:
    // 每个线程的自由链表数组
    std::array<void*, FREE_LIST_SIZE> freeList_;    
};

//ThreadCache.cpp
void* ThreadCache::allocate(size_t size)
        return malloc(size);
    }

    size_t index = SizeClass::getIndex(size);

    // 检查线程本地自由链表
    // 如果 freeList_[index] 不为空，表示该链表中有可用内存块
    if (void* ptr = freeList_[index])
    {
        freeList_[index] = *reinterpret_cast<void**>(ptr); // 将freeList_[index]指向的内存块的下一个内存块地址（取决于内存块的实现）
        return ptr;
    }

    // 如果线程本地自由链表为空，则从中心缓存获取一批内存
    return fetchFromCentralCache(index);
}

void ThreadCache::deallocate(void* ptr, size_t size)
{
    if (size > MAX_BYTES)
    {
        free(ptr);
        return;
    }

    size_t index = SizeClass::getIndex(size);

    // 插入到线程本地自由链表
    *reinterpret_cast<void**>(ptr) = freeList_[index];
    freeList_[index] = ptr;
}

void* ThreadCache::fetchFromCentralCache(size_t index)
{
    // 从中心缓存批量获取内存
    void* start = CentralCache::getInstance().fetchRange(index);
    if (!start) return nullptr;

    // 取一个返回，其余放入自由链表
    void* result = start;
    freeList_[index] = *reinterpret_cast<void**>(start);
    
    return result;
}

void ThreadCache::returnToCentralCache(void* start, size_t size, size_t bytes)
{
    // 根据大小计算对应的索引
    size_t index = SizeClass::getIndex(size);

    // 计算要归还内存块数量
    size_t batchNum = size / bytes;
    if (batchNum <= 1) return; // 如果只有一个块，则不归还

    // 将内存块串成链表
    char* current = static_cast<char*>(start);
    // 删除未使用的变量 end
    // char* end = current + (batchNum - 1) * bytes;

    // 保留一部分在ThreadCache中（比如保留1/4）
    size_t keepNum = std::max(batchNum / 4, size_t(1));
    size_t returnNum = batchNum - keepNum;

    // 计算要保留的最后一个节点位置
    char* splitNode = current + (keepNum - 1) * bytes;

    // 将要返回的部分和要保留的部分断开
    void* nextNode = *reinterpret_cast<void**>(splitNode);
    *reinterpret_cast<void**>(splitNode) = nullptr; // 断开连接

    // 更新ThreadCache的空闲链表
    freeList_[index] = start;

    // 将剩余部分返回给CentralCache
    if (returnNum > 0)
    {
        char* returnStart = static_cast<char*>(nextNode);
        CentralCache::getInstance().returnRange(returnStart, returnNum * bytes, index);
    }
}

```

### 中心缓存(CentralCache)

#### 中心缓存介绍
##### CentralCache的定位和作用
```
class CentralCache {
private:
    // 中心缓存的自由链表数组
    std::array<std::atomic<void*>, FREE_LIST_SIZE> centralFreeList_;
    // 自旋锁数组，用于保护每个链表
    std::array<std::atomic_flag, FREE_LIST_SIZE> locks_;
};
```
主要作用：  
●作为ThreadCache和PageCache之间的中间层  
●管理从PageCache获取的内存块  
●为多个ThreadCache提供内存分配服务  
●实现内存的跨线程复用

##### 核心实现原理

```
void* CentralCache::fetchRange(size_t index)
{
    // 1. 检查并获取锁
    while (locks_[index].test_and_set(std::memory_order_acquire));
    
    // 2. 尝试从现有链表获取
    void* result = centralFreeList_[index].load(std::memory_order_relaxed);
    
    // 3. 如果没有可用内存，从PageCache批量申请
    if (!result) {
        result = fetchFromPageCache(size);
        // 切分成小块并构建链表
    }
    
    // 4. 更新链表头并返回
    centralFreeList_[index].store(
        *reinterpret_cast<void**>(result), 
        std::memory_order_release
    );
    
    return result;
}
```
##### 设计特点

批量管理  
`static const size_t SPAN_PAGES = 8; // 固定8页的批量申请`

原因：  
●减少向PageCache的请求次数  
●提高内存分配效率  
●降低锁竞争  
2细粒度锁  
●减少线程竞争  
●提高并发性能  
●避免全局锁的性能瓶颈

##### 工作流程

```
// 1. ThreadCache请求内存
void* ThreadCache::fetchFromCentralCache(size_t index) {
    return CentralCache::getInstance().fetchRange(index);
}

// 2. CentralCache处理请求
void* CentralCache::fetchRange(size_t index) {
    // 如果centralFreeList_中有可用内存
    if (result = centralFreeList_[index].load()) {
        return result;
    }
    
    // 否则从PageCache获取新内存
    result = fetchFromPageCache(size);
    // 切分并构建链表
    return result;
}

// 3. 内存回收
void CentralCache::returnRange(void* start, size_t size, size_t index) {
    // 将内存块插入到对应的自由链表
    *reinterpret_cast<void**>(start) = centralFreeList_[index].load();
    centralFreeList_[index].store(start);
}
```

##### 为什么这么设计

1三级缓存的必要性  
aThreadCache：无锁，快速分配  
bCentralCache：平衡点，内存复用  
cPageCache：系统对接，大块管理  
2批量处理的优势  
a减少锁竞争  
b提高缓存命中率  
c降低系统调用开销  
3内存规格管理  
​
`size_t size = (index + 1) * ALIGNMENT; // 8字节对齐`

原因：  
●减少内存碎片  
●提高内存利用率  
●简化管理逻辑  
性能考虑  
●空间效率：批量申请和释放  
●时间效率：细粒度锁和原子操作  
●并发性能：多线程友好设计  
●缓存友好：连续内存布局  
这种设计在以下场景特别有效：  
●高并发应用  
●频繁的内存分配/释放  
●多线程环境  
●对性能要求高的系统  
CentralCache的实现体现了内存管理中"平衡"的思想，在效率、并发性、复杂度等多个维度之间取得了很好的平衡。

#### 项目完整代码