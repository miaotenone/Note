## 内存管理

### 虚拟内存
#### 为什么要使用虚拟内存

单⽚机的 CPU 是直接操作内存的「物理地址」 。
![[单片机cpu操作地址.png]]
在这种情况下，要想在内存中同时运⾏两个程序是不可能的。

我们可以**把进程所使⽤的地址「隔离」开来**，即让操作系统**为每个进程分配独⽴的⼀套「虚拟地址」**，⼈⼈都有，⼤家⾃⼰玩⾃⼰的地址就⾏，互不⼲涉。但是有个前提每个进程都不能访问物理地址，⾄于虚拟地址最终怎么落到物理内存⾥，对进程来说是透明的，操作系统已经把这些都安排的明明⽩⽩了
![[虚拟内存.png|214]]
**操作系统会提供⼀种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**
如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运⾏的时候，写⼊的是不同的物理地址，这样就不会冲突了。

于是，这⾥就引出了两种地址的概念：
我们程序所使⽤的内存地址叫做**虚拟内存地址**（Virtual Memory Address）
实际存在硬件⾥⾯的空间地址叫**物理内存地址**（Physical Memory Address）。
操作系统引⼊了**虚拟内存**，进程持有的虚拟地址会通过 CPU 芯⽚中的**内存管理单元（MMU）** 的**映射关系**，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：
![[内存映射.png]]
操作系统是如何管理虚拟地址与物理地址之间的关系？**内存分段和内存分⻚**

### 内存分段
程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。 不同的段是有不同的属性的，所以就⽤**分段（Segmentation）** 的形式把这些段分离出来。
分段机制下，虚拟地址和物理地址是如何映射的？
分段机制下的虚拟地址由两部分组成， 段选择⼦和段内偏移量。
![[内存分段流程.png]]
- 段选择⼦就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是段号，⽤作段表的索引。 段表⾥⾯保存的是这个段的基地址、段的界限和特权等级等。
- 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
在上⾯，知道了虚拟地址是通过段表与物理地址进⾏映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有⼀个项，在这⼀项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：
![[内存分段映射.png]]
如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

分段的办法很好，解决了程序本身不需要关⼼具体的物理内存地址的问题，但它也有⼀些不⾜之处：

- 第⼀个就是内存碎⽚的问题。

- 第⼆个就是内存交换的效率低的问题。

接下来，说说为什么会有这两个问题。

我们先来看看，分段为什么会产⽣内存碎⽚的问题？

我们来看看这样⼀个例⼦。假设有 1G 的物理内存，⽤户执⾏了多个程序，其中：

- 游戏占⽤了 512MB 内存
- 浏览器占⽤了 128MB 内存
- ⾳乐占⽤了 256 MB 内存。

这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开⼀个 200MB 的程序。
![[内存分段示例.png]]
这⾥的内存碎⽚的问题共有两处地⽅：
外部内存碎⽚，也就是产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载；
内部内存碎⽚，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使⽤，这也会导致内存的浪费；
针对上⾯两种内存碎⽚的问题，解决的⽅式会有所不同。
解决外部内存碎⽚的问题就是内存交换。
可以把⾳乐程序占⽤的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存⾥。不过再读回的时候，我们不能装载回原来的位置，⽽是紧紧跟着那已经被占⽤了的 512MB 内存后⾯。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。
这个内存交换空间，在 Linux 系统⾥，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，⽤于内存与硬盘的空间交换。
再来看看，分段为什么会导致内存交换效率低的问题？
对于多进程的系统来说，⽤分段的⽅式，内存碎⽚是很容易产⽣的，产⽣了内存碎⽚，那不得不重新Swap 内存区域，这个过程会产⽣性能瓶颈。
因为硬盘的访问速度要⽐内存慢太多了，每⼀次内存交换，我们都需要把⼀⼤段连续的内存数据写到硬盘上。
所以， 如果内存交换的时候，交换的是⼀个占内存空间很⼤的程序，这样整个机器都会显得卡顿。
为了解决内存分段的内存碎⽚和内存交换效率低的问题，就出现了内存分⻚。

### 内存分页
分段的好处就是能产⽣连续的内存空间，但是会出现内存碎⽚和内存交换的空间太⼤的问题。

要解决这些问题，那么就要想出能少出现⼀些内存碎⽚的办法。另外，当需要进⾏内存交换的时候，让需要交换写⼊或者从磁盘装载的数据更少⼀点，这样就可以解决问题了。这个办法，也就是内存分⻚（Paging）。

分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。这样⼀个连续并且尺⼨固定的内存空间，我们叫⻚（Page）。在 Linux 下，每⼀⻚的⼤⼩为 4KB 。

虚拟地址与物理地址之间通过⻚表来映射，如下图：
![[页表映射.png]]
⻚表是存储在内存⾥的， 内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯作。

⽽当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

分⻚是怎么解决分段的内存碎⽚、内存交换效率低的问题？

由于内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常⼩的内存，这正是分段会产⽣内存碎⽚的原因。⽽采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存。

如果内存空间不够，操作系统会把其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。⼀旦需要的时候，再加载进来，称为换⼊（Swap In）。所以，⼀次性写⼊磁盘的也只有少数的⼀个⻚或者⼏个⻚，不会花太多时间， 内存交换的效率就相对⽐较⾼。
![[内存分页.png]]
更进⼀步地，分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理内存中。我们完全可以在进⾏虚拟内存和物理内存的⻚之间的映射之后，并不真的把⻚加载到物理内存⾥，⽽是只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。

分⻚机制下，虚拟地址和物理地址是如何映射的？

在分⻚机制下，虚拟地址分为两部分， ⻚号和⻚内偏移。⻚号作为⻚表的索引， ⻚表包含物理⻚每⻚所在物理内存的基地址，这个基地址与⻚内偏移的组合就形成了物理内存地址，⻅下图。
![[内存分页1.png]]
总结⼀下，对于⼀个内存地址转换，其实就是这样三个步骤：
把虚拟内存地址，切分成⻚号和偏移量；
根据⻚号，从⻚表⾥⾯，查询对应的物理⻚号；
直接拿物理⻚号，加上前⾯的偏移量，就得到了物理内存地址。
下⾯举个例⼦，虚拟内存中的⻚通过⻚表映射为了物理内存中的⻚，如下图：
![[内存分页2.png]]
这看起来似乎没什么⽑病，但是放到实际中操作系统，这种简单的分⻚是肯定是会有问题的。
简单的分⻚有什么缺陷吗？
有空间上的缺陷。
因为操作系统是可以同时运⾏⾮常多的进程的，那这不就意味着⻚表会⾮常的庞⼤。
在 32 位的环境下，虚拟地址空间共有 4GB，假设⼀个⻚的⼤⼩是 4KB（2^12），那么就需要⼤约 100 万（2^20） 个⻚，每个「⻚表项」需要 4 个字节⼤⼩来存储，那么整个 4GB 空间的映射就需要有 4MB的内存来存储⻚表。
这 4MB ⼤⼩的⻚表，看起来也不是很⼤。但是要知道每个进程都是有⾃⼰的虚拟地址空间的，也就说都有⾃⼰的⻚表。
那么， 100 个进程的话，就需要 400MB 的内存来存储⻚表，这是⾮常⼤的内存了，更别说 64 位的环境了。

#### 多级页表
要解决上⾯的问题，就需要采⽤⼀种叫作多级⻚表（Multi-Level Page Table）的解决⽅案。

在前⾯我们知道了，对于单⻚表的实现⽅式，在 32 位和⻚⼤⼩ 4KB 的环境下，⼀个进程的⻚表需要装下 100 多万个「⻚表项」，并且每个⻚表项是占⽤ 4 字节⼤⼩的，于是相当于每个⻚表需占⽤ 4MB ⼤⼩的空间。

我们把这个 100 多万个「⻚表项」的单级⻚表再分⻚，将⻚表（⼀级⻚表）分为 1024 个⻚表（⼆级⻚表），每个表（⼆级⻚表）中包含 1024 个「⻚表项」，形成⼆级分⻚。如下图所示：
![[多级页表.png]]
你可能会问，分了⼆级表，映射 4GB 地址空间就需要 4KB（⼀级⻚表） + 4MB（⼆级⻚表）的内存，这样占⽤空间不是更⼤了吗？

当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，⼆级分⻚占⽤空间确实是更⼤了，但是，我们往往不会为⼀个进程分配那么多内存。

其实我们应该换个⻆度来看问题，还记得计算机组成原理⾥⾯⽆处不在的局部性原理么？

每个进程都有 4GB 的虚拟地址空间，⽽显然对于⼤多数程序来说，其使⽤到的空间远未达到 4GB，因为会存在部分对应的⻚表项都是空的，根本没有分配，对于已分配的⻚表项，如果存在最近⼀定时间未访问的⻚表，在物理内存紧张的情况下，操作系统会将⻚⾯换出到硬盘，也就是说不会占⽤物理内存。

如果使⽤了⼆级分⻚，⼀级⻚表就可以覆盖整个 4GB 虚拟地址空间，但如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。做个简单的计算，假设只有 20% 的⼀级⻚表项被⽤到了，那么⻚表占⽤的内存空间就只有 4KB（⼀级⻚表） + 20% * 4MB（⼆级⻚表） = 0.804MB ，这对⽐单级⻚表的 4MB 是不是⼀个巨⼤的节约？

那么为什么不分级的⻚表就做不到这样节约内存呢？我们从⻚表的性质来看，保存在内存中的⻚表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在⻚表中找不到对应的⻚表项，计算机系统就不能⼯作了。所以⻚表⼀定要覆盖全部虚拟地址空间，不分级的⻚表就需要有 100 多万个⻚表项来映射，⽽⼆级分⻚则只需要 1024 个⻚表项（此时⼀级⻚表覆盖到了全部虚拟地址空间，⼆级⻚表在需要时创建）。

我们把⼆级分⻚再推⼴到多级⻚表，就会发现⻚表占⽤的内存空间更少了，这⼀切都要归功于对局部性原理的充分应⽤。

对于 64 位的系统，两级分⻚肯定不够了，就变成了四级⽬录，分别是：

全局⻚⽬录项 PGD（Page Global Directory）；上层⻚⽬录项 PUD（Page Upper Directory）；中间⻚⽬录项 PMD（Page Middle Directory）；⻚表项 PTE（Page Table Entry）；
![[多级页表1.png]]


#### TLB
多级⻚表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了⼏道转换的⼯序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

程序是有局部性的，即在⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域。
![[tlb.png]]
我们就可以利⽤这⼀特性，把最常访问的⼏个⻚表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯⽚中，加⼊了⼀个专⻔存放程序最常访问的⻚表项的 Cache，这个 Cache 就是 TLB （Translation Lookaside Buffer） ，通常称为⻚表缓存、转址旁路缓存、快表等
![[tlb1.png]]
在 CPU 芯⽚⾥⾯，封装了内存管理单元（Memory Management Unit）芯⽚，它⽤来完成地址转换和 TLB的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的⻚表。

TLB 的命中率其实是很⾼的，因为程序最常访问的⻚就那么⼏个。



### 段页式内存管理
内存分段和内存分⻚并不是对⽴的，它们是可以组合起来在同⼀个系统中使⽤的，那么组合起来后，通常称为段⻚式内存管理.
![[段页式内存管理.png]]
段⻚式内存管理实现的⽅式：

先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；

接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚；

这样，地址结构就由段号、段内⻚号和⻚内位移三部分组成。

⽤于段⻚式地址变换的数据结构是每⼀个程序⼀张段表，每个段⼜建⽴⼀张⻚表，段表中的地址是⻚表的起始地址，⽽⻚表中的地址则为某⻚的物理⻚号，如图所示：
![[段页式内存管理1.png]]
段⻚式地址变换中要得到物理地址须经过三次内存访问：

第⼀次访问段表，得到⻚表起始地址；第⼆次访问⻚表，得到物理⻚号；

第三次将物理⻚号与⻚内位移组合，得到物理地址。

可⽤软、硬件相结合的⽅法实现段⻚式地址变换，这样虽然增加了硬件成本和系统开销，但提⾼了内存的利⽤率。


### Linux内存管理
那么， Linux 操作系统采⽤了哪种⽅式来管理内存呢？

在回答这个问题前，我们得先看看 Intel 处理器的发展历史。

早期 Intel 的处理器从 80286 开始使⽤的是段式内存管理。但是很快发现，光有段式内存管理⽽没有⻚式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争⼒。因此，在不久以后的 80386 中就实现了对⻚式内存管理。也就是说， 80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了⻚式内存管理。

但是这个 80386 的⻚式内存管理设计时，没有绕开段式内存管理，⽽是建⽴在段式内存管理的基础上，这就意味着， ⻚式内存管理的作⽤是在由段式内存管理所映射⽽成的地址上再加上⼀层地址映射。

由于此时由段式内存管理映射⽽成的地址不再是“物理地址”了， Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由⻚式内存管理将线性地址映射成物理地址。
![[Linux内存管理.png]]
这⾥说明下逻辑地址和线性地址：

程序所使⽤的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；

逻辑地址是「段式内存管理」转换前的地址，线性地址则是「⻚式内存管理」转换前的地址。

了解完 Intel 处理器的发展历史后，我们再来说说 Linux 采⽤了什么⽅式管理内存？

Linux 内存主要采⽤的是⻚式内存管理，但同时也不可避免地涉及了段机制。

这主要是上⾯ Intel 处理器发展历史导致的，因为 Intel X86 CPU ⼀律对程序中使⽤的地址先进⾏段式映射，然后才能进⾏⻚式映射。既然 CPU 的硬件结构是这样， Linux 内核也只好服从 Intel 的选择。

但是事实上， Linux 内核所采取的办法是使段式映射的过程实际上不起什么作⽤。也就是说， “上有政策，下有对策”，若惹不起就躲着⾛。

Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是⼀样的。这意味着， Linux 系统中的代码，包括操作系统本身的代码和应⽤程序代码，所⾯对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被⽤于访问控制和内存保护。

我们再来瞧⼀瞧， Linux 的虚拟地址空间是如何分布的？

在 Linux 操作系统中，虚拟地址空间的内部⼜被分为内核空间和⽤户空间两部分，不同位数的系统，地址空间的范围也不同。⽐如最常⻅的 32 位和 64 位系统，如下所示：
![[Linux内存管理1.png]]
通过这⾥可以看出：

32 位系统的内核空间占⽤ 1G ，位于最⾼处，剩下的 3G 是⽤户空间；

64 位系统的内核空间和⽤户空间都是 128T ，分别占据整个内存空间的最⾼和最低处，剩下的中

间部分是未定义的。

再来说说，内核空间与⽤户空间的区别：

进程在⽤户态时，只能访问⽤户空间内存；

只有进⼊内核态后，才可以访问内核空间的内存；

虽然每个进程都各⾃有独⽴的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很⽅便地访问内核空间内存。
![[Linux内存管理2.png]]
接下来，进⼀步了解虚拟空间的划分情况，⽤户空间和内核空间划分的⽅式是不同的，内核空间的分布情况就不多说了。

我们看看⽤户空间分布的情况，以 32 位系统为例，我画了⼀张图来表示它们的关系：
![[Linux内存管理3.png|375]]
通过这张图你可以看到，⽤户空间内存，从低到⾼分别是 7 种不同的内存段：
程序⽂件段，包括⼆进制可执⾏代码；
已初始化数据段，包括静态常量；
未初始化数据段，包括未初始化的静态变量；
堆段，包括动态分配的内存，从低地址开始向上增⻓；
⽂件映射段，包括动态库、共享内存等，从低地址开始向上增⻓（跟硬件和内核版本有关）；
栈段，包括局部变量和函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB 。当然系统也提供了参数，以便我们⾃定义⼤⼩；
在这 7 个内存段中，堆和⽂件映射段的内存是动态分配的。⽐如说，使⽤ C 标准库的 malloc() 或者mmap() ，就可以分别在堆和⽂件映射段动态分配内存。




## 进程与线程
### 进程

#### 并发和并⾏有什么区别？
**并发（Concurrency）**：
1. 多个任务在同一时间段内交替进行。
2. 任务切换提高响应性和资源利用率。
3. 可以在单核处理器上实现。
4. 任务之间是交替执行的，给人一种同时进行的错觉。

**并行（Parallelism**）：
1. 多个任务在同一时刻同时进行。
2. 需要多核处理器或多个处理器。
3. 提高计算速度和处理能力。
4. 任务之间是真正的同时执行。

**应用场景**
并发： 适用于 **I/O 密集型任务**（如文件读取、网络通信） ，可以提高系统的响应性。
并行： 适用于**计算密集型任务**（如矩阵乘法、大数据处理） ，可以显著缩短计算时间。
![[进程2.png]]


#### 进程的状态
**进程的活动期间⾄少具备三种基本状态，即运⾏状态、就绪状态、阻塞状态**
![[进程的状态.png]]
- **运⾏状态**（Runing）：该时刻进程占⽤ CPU；
- **就绪状态**（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；
- **阻塞状态**（Blocked）：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏；
- **创建状态**（new）：进程正在被创建时的状态；
- **结束状态**（Exit）：进程正在从系统中消失时的状态；
- **挂起状态**: 描述进程没有占⽤实际的物理内存空间的情况
	- **阻塞挂起状态**：进程在外存（硬盘）并等待某个事件的出现；
	- **就绪挂起状态**：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；


#### 进程的控制结构(PCB)的作用或者包含了什么信息

(1)**唯一标识进程**： 通过进程标识符 (PID) 唯一标识每个进程。
(2)**存储进程状态**： 记录进程的当前状态，如运行、就绪、等待等。
(3)**保存寄存器上下文**： 保存进程的 CPU 寄存器值，如程序计数器、栈指针等，用于上下文切换。
(4)**管理内存分配**： 跟踪进程的内存使用情况，包括代码段、数据段、堆、栈等。
(5)**文件描述符表**： 记录进程打开的文件及其对应的文件描述符。
(6)**进程调度信息**： 包含进程的优先级、时间片等调度相关信息。
(7)**进程间通信**： 管理进程间通信的相关信息，如管道、消息队列、共享内存等。

#### 进程的创建需要系统分配什么资源
1. **内存空间**
	- 代码段： 存储程序的可执行代码。每个进程都会分配一个代码段，用于存放程序指令。
	- 数据段： 存储全局变量和静态变量。数据段在程序运行期间保持固定大小。
	- 堆区： 用于动态内存分配。在程序运行期间，可以通过 malloc 或 new 动态分配和释放内存。
	- 栈区： 用于存储局部变量和函数调用栈帧。每次函数调用都会在栈上分配新的栈帧。
2. **进程控制块 (PCB)**
	- 进程状态： 表示进程当前的状态，如运行、就绪、等待等。
	- 寄存器上下文： 保存进程的 CPU 寄存器值，包括程序计数器、栈指针等，用于在上下文切换时恢复进程的执行状态。
	- 调度信息： 包含进程优先级、调度队列等信息，用于操作系统调度进程。
3. **文件描述符**
	每个进程都有一个文件描述符表，存储进程打开的文件及其对应的文件描述符。
4. **进程号 (PID)**
	每个进程都有一个唯一的进程号 (PID)，用于标识进程。
5. **CPU 时间片**
	操作系统为每个进程分配 CPU 时间片，用于进程调度和执行。
6. **系统资源和权限**
	包括网络连接、设备访问权限等。操作系统在创建进程时会为其分配必要的系统资源和权限。

#### 进程的上下文切换


### 线程
#### 核心目的
线程是操作系统调度的最小单位，允许在**同一进程内并行执行多个任务**（共享内存空间）。

#### 什么是线程？
线程是进程当中的⼀条执⾏流程。
同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的

#### 优缺点
**优点**
1. ⼀个进程中可以同时存在多个线程；
2. 各个线程之间可以并发执⾏；
3. 各个线程之间可以共享地址空间和⽂件等资源；

**缺点**
1. 当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃。

#### 线程与进程的比较
- 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执⾏的时间和空间开销；
	- 线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；
	- 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
	- 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；
	- 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了；

#### 线程的上下文切换
当两个线程**不是属于**同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
当两个线程是**属于**同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

- 资源共享： 共享内容： 线程共享进程的内存空间（代码段、数据段和打开的文件等），但各自持有独立的栈（用于存储执行历史）、寄存器状态和程序计数器。 独立内容：线程栈、局部变量、寄存器和程序计数器等。
- 上下文切换： 涉及内容：切换线程时，主要保存和恢复寄存器状态、程序计数器和栈的指针。开销：相较于进程切换，线程切换的开销小，因为不需要切换内存地址空间。


#### 线程的实现


#### 线程间通信
![[线程间通信.png]]


### 调度

#### 调度时机

#### 调度原则

#### 调度算法

### ==进程间通信（超高频）==

**基本原理**：每个进程的⽤户空间都是独⽴的，不能相互访问，但是共享一个内核空间

**管道**
数据缓存在内核中，遵循先进先出原则，不⽀持 lseek 之类的⽂件定位操作
匿名管道
1. 数据：**⽆格式的流并且⼤⼩受限**
2. 方向：单向
3. 只能⽤于存在**⽗⼦关系的进程间**通信
4. **⽣命周期**：随着进程创建⽽建⽴，随着进程终⽌⽽消失

命名管道
1.  非父子关系的进程间也可以通信（在⽂件系统创建⼀个类型为 p 的设备⽂件，通过这个文件通信）

**消息队列**
1. 克服了管道通信的数据是**⽆格式的字节流的问题**和管道**不能频繁交换数据**的问题
2. 消息队列实际上是保存在内核的「**消息链表**」消息队列的消息体是可以⽤户**⾃定义的数据类型**，发送数据会被分成⼀个个**独⽴的消息体**。
3. 速度不是最及时的，毕竟每次数据的写⼊和读取都需要经过⽤户态与内核态之间的**拷⻉过程**。


**共享内存**
1. 两个进程拿出⼀块虚拟地址空间来，映射到相同的物理内存中---->解决了消息队列通信中⽤户态与内核态之间数据**拷⻉过程带来的开销**
2. **通信的速度快**，最快的进程间通信⽅式
3. 带来了**多线程竞争同个共享资源**的问题


**信号量**
1. 保护共享资源，以确保任何时刻只能有⼀个进程访问共享资源--->互斥访问
2. 实现进程间的同步
3. 原理：信号量其实是⼀个计数器，表示的是资源个数，其值可以通过两个原⼦操作来控制，分别是 P 操作和 V 操作。

**信号**
1. 进程间通信唯⼀的异步通信机制
2. 应用场景: 异常情况下的⼯作模式，使用信号通知进程
3. 原理：信号在**应⽤进程和内核之间直接交互**，内核也可以利⽤信号来**通知⽤户空间的进程发⽣了哪些系统事件**，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），⼀旦有信号发⽣， 进程有三种⽅式响应信号 1. 执⾏默认操作、 2. 捕捉信号、 3. 忽略信号。有两个信号是应⽤进程⽆法捕捉和忽略的，即 SIGKILL 和 SEGSTOP ，这是为了⽅便我们能在任何时候结束或停⽌某个进程。

**Socket 通信**
1. 应用于**本地主机进程间通信和跨网络和不同主机进程通信**
2. 三种通信方式：基于TCP、基于UDP、本地进程间通信




### 多线程同步

#### 竞争与协作

#### 互斥与同步

#### 经典同步问题



### 死锁
### 死锁的概念

### 模拟死锁问题的产生

### 利用工具排查死锁问题

### 避免死锁问题的发生

### 悲观锁与乐观锁

#### 互斥锁与自旋锁

#### 读写锁

#### 乐观锁与悲观锁


## 调度算法

### 进程调度算法

#### 先来先服务调度算法

#### 最短作业优先调度算法

#### 高响应比优先调度算法

#### 时间片轮转调度算法

#### 最高优先级调度算法

#### 多级反馈队列调度算法

### 内存页面置换算法

#### 最佳页面置换算法

#### 先进先出置换算法

#### 最近最久未使用的置换算法

#### 时钟页面置换算法

#### 最不常用算法

### 磁盘调度算法

#### 先来先服务

#### 最短寻道时间优先


### 扫描算法

#### 循环扫描算法

#### LOOK 与 C-LOOK算法



## 文件系统

### Linux软链接和硬链接


## 网络系统

### Linux 系统是如何收发网络包的？

#### 网络模型

#### Linux 网络协议栈

#### Linux 接收网络包的流程

#### Linux 发送网络包的流程
### 零拷贝



#### 为什么要有 DMA 技术?

#### 传统的文件传输有多糟糕？

#### 如何优化文件传输的性能？

#### 如何实现零拷贝？

##### mmap + write

##### sendfile

##### 使用零拷贝技术的项目
#### PageCache 有什么作用？

#### 大文件传输用什么方式实现？


### I/O 多路复用：select/poll/epoll

#### 最基本的 Socket 模型

#### 如何服务更多的用户？

#### 多进程模型

#### 多线程模型

#### I/O 多路复用

#### select/poll

#### epoll

### 高性能网络模式：Reactor 和 Proactor

#### Reactor

#### Proactor

